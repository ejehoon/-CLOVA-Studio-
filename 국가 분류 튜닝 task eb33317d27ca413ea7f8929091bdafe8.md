# 국가 분류 튜닝 task

Status: 시작 전


![스크린샷 2024-06-09 오후 8.10.45.png](https://github.com/ejehoon/NAVER_CLOUD-CLOVA_Studio/blob/main/%EA%B5%AD%EA%B0%80%20%EB%B6%84%EB%A5%98%20%ED%8A%9C%EB%8B%9D%20task/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-06-09_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_8.10.45.png)

이 cookbook에서는 CLOVA Studio의 튜닝 API(학습 생성 API, 학습 조회 API, Completion API, Chat Completion API)를 사용하여 분류 문제를 해결하는 과정을 자세히 소개합니다. 국가 분류 작업을 예시로 들어, 분류 작업 중 발생하는 누락이나 오분류 등의 문제를 어떻게 해결했는지 자세히 설명합니다. 특히, HCX-003과 HCX-DASH-001 모델의 튜닝 데이터 개수를 늘려가며 비교한 결과를 통해 각 모델의 튜닝 적정 개수 차이를 알아볼 수 있습니다. 이를 통해 모델 튜닝을 효과적으로 활용하여 분류 작업의 정확성을 높이는 방법을 배울 수 있습니다.

- 버전 정보
  ```python
  Python 3.12.2

  import base64
  import csv
  import http.client
  import json
  import pandas as pd
  import random
  import requests
  import time

  api_credentials = {
      'host': 'api-hyperclova.navercorp.com',
      'client_id': '<client_id>',
      'client_secret': '<client_secret>'
  }
  ```

데이터셋 준비

### UN 회원국 목록 크롤링

국가 분류 작업 중 발생하는 누락이나 오분류 문제를 줄이기 위해 UN 회원국 192개국을 크롤링하여 데이터를 수집했습니다. UN 회원국 목록을 대륙별로 분류한 데이터를 기반으로 하여 딕셔너리 형태로 저장하였습니다. 이 데이터를 사용하여 모델을 튜닝하고 학습시킴으로써, 국가 분류 작업의 정확성을 높이고 오류 발생 확률을 줄이려는 목적이 있습니다.

- UN 회원국 목록 크롤링
  ```python
  un_countries = {
      "아시아": ["아프가니스탄", "방글라데시", "부탄", "브루나이", "캄보디아", "중국", "키프로스", "동티모르", "인도", "인도네시아", "이란", "이라크", "이스라엘", "일본", "요르단", "카자흐스탄", "북한", "대한민국", "쿠웨이트", "키르기스스탄", "라오스", "바레인", "레바논", "말레이시아", "몰디브", "몽골", "미얀마", "네팔", "오만", "파키스탄", "필리핀", "카타르", "러시아", "사우디아라비아", "싱가포르", "스리랑카", "시리아", "타지키스탄", "태국", "튀르키예", "투르크메니스탄", "아랍 에미리트", "우즈베키스탄", "베트남", "예멘"],
      "유럽": ["알바니아", "안도라", "아르메니아", "오스트리아", "아제르바이잔", "벨라루스", "벨기에", "보스니아 헤르체고비나", "불가리아", "크로아티아", "체코", "덴마크", "에스토니아", "핀란드", "프랑스", "조지아", "독일", "그리스", "헝가리", "아이슬란드", "아일랜드", "이탈리아", "라트비아", "리히텐슈타인", "리투아니아", "룩셈부르크", "몰타", "몰도바", "모나코", "몬테네그로", "네덜란드", "북마케도니아", "노르웨이", "폴란드", "포르투갈", "루마니아", "산마리노", "세르비아", "슬로바키아", "슬로베니아", "스페인", "스웨덴", "스위스", "우크라이나", "영국"],
      "북아메리카": ["앤티가 바부다", "바하마", "바베이도스", "벨리즈", "캐나다", "코스타리카", "쿠바", "도미니카", "도미니카 공화국터", "엘살바도르", "그레나다", "과테말라", "아이티", "온두라스", "자메이카", "멕시코", "니카라과", "파나마", "세인트 키츠 네비스", "세인트 루시아", "세인트 빈센트 그레나딘", "트리니다드 토바고", "미국"],
      "남아메리카": ["아르헨티나", "볼리비아", "브라질", "칠레", "콜롬비아", "에콰도르", "가이아나", "파라과이", "페루", "수리남", "우루과이", "베네수엘라"],
      "아프리카": ["알제리", "앙골라", "베냉", "보츠와나", "부르키나파소", "부룬디", "카보베르데", "카메룬", "중앙아프리카 공화국", "차드", "코모로", "콩고", "코트디부아르", "지부티", "이집트", "적도 기니", "에리트레아", "에스와티니", "에티오피아", "가봉", "감비아", "가나", "기니", "기니비사우", "케냐", "레소토", "라이베리아", "리비아", "마다가스카르", "말라위", "말리", "모리타니아", "모리셔스", "모로코", "모잠비크", "나미비아", "니제르", "나이지리아", "르완다", "상투메 프린시페", "세네갈", "세이셸", "시에라리온", "소말리아", "남아프리카 공화국", "남수단", "수단", "탄자니아", "토고", "튀니지", "우간다", "잠비아", "짐바브웨"],
      "오세아니아": ["오스트레일리아", "피지", "키리바시", "마셜 제도", "미크로네시아 연방", "나우루", "뉴질랜드", "팔라우", "파푸아뉴기니", "사모아", "솔로몬 제도", "통가", "투발루", "바누아투"]
  }
  ```

**도움말**

튜닝 데이터의 품질과 신뢰도는 모델 성능에 직접적인 영향을 미칩니다. 따라서 신뢰할 수 있는 출처에서 데이터를 수집하고, 엄밀하게 분류하여 사용하는 것이 중요합니다.

### 튜닝용 데이터셋 생성

모델 튜닝을 위해 크롤링한 데이터를 기반으로 다양한 국가 개수와 대륙 개수로 구성된 데이터셋을 생성하는 Python 코드를 작성하였습니다.

이 코드를 사용하면 원하는 데이터 개수와 국가 수를 선택하여 데이터셋을 생성할 수 있습니다. 생성된 데이터셋은 2개 대륙부터 6개 대륙까지 균등한 비율로 구성됩니다.

플레이그라운드 화면에서 정성 평가를 진행한 결과, 12개국을 기준으로 오류가 많이 발생하는 것을 확인하였습니다.

이 결과를 바탕으로, 모델의 분류 정확도를 향상시키기 위해 데이터셋의 국가 개수를 10개국, 15개국, 20개국, 30개국으로 다양하게 구성하였으며, 각각의 비율은 1:3:3:3으로 설정하였습니다.

선택된 국가들은 랜덤하게 섞어 데이터셋의 텍스트(Text)로 사용되며, 해당 국가들을 대륙별로 분류한 결과가 완성 텍스트(Completion)로 사용됩니다. 생성된 데이터셋은 CSV 파일로 저장됩니다.

이 코드를 활용하면 다양한 국가 개수와 대륙 개수로 구성된 데이터셋을 손쉽게 생성할 수 있으며, 생성된 데이터셋을 사용하여 모델의 성능을 평가하고 개선할 수 있습니다.

```python
import random
import csv
```

```python
# UN에 가입된 국가들을 대륙별로 분류한 딕셔너리
un_countries = {
    "아시아": ["아프가니스탄", "방글라데시", "부탄", "브루나이", "캄보디아", "중국", "키프로스", "동티모르", "인도", "인도네시아", "이란", "이라크", "이스라엘", "일본", "요르단", "카자흐스탄", "북한", "대한민국", "쿠웨이트", "키르기스스탄", "라오스", "바레인", "레바논", "말레이시아", "몰디브", "몽골", "미얀마", "네팔", "오만", "파키스탄", "필리핀", "카타르", "러시아", "사우디아라비아", "싱가포르", "스리랑카", "시리아", "타지키스탄", "태국", "튀르키예", "투르크메니스탄", "아랍 에미리트", "우즈베키스탄", "베트남", "예멘"],
    "유럽": ["알바니아", "안도라", "아르메니아", "오스트리아", "아제르바이잔", "벨라루스", "벨기에", "보스니아 헤르체고비나", "불가리아", "크로아티아", "체코", "덴마크", "에스토니아", "핀란드", "프랑스", "조지아", "독일", "그리스", "헝가리", "아이슬란드", "아일랜드", "이탈리아", "라트비아", "리히텐슈타인", "리투아니아", "룩셈부르크", "몰타", "몰도바", "모나코", "몬테네그로", "네덜란드", "북마케도니아", "노르웨이", "폴란드", "포르투갈", "루마니아", "산마리노", "세르비아", "슬로바키아", "슬로베니아", "스페인", "스웨덴", "스위스", "우크라이나", "영국"],
    "북아메리카": ["앤티가 바부다", "바하마", "바베이도스", "벨리즈", "캐나다", "코스타리카", "쿠바", "도미니카", "도미니카 공화국", "엘살바도르", "그레나다", "과테말라", "아이티", "온두라스", "자메이카", "멕시코", "니카라과", "파나마", "세인트 키츠 네비스", "세인트 루시아", "세인트 빈센트 그레나딘", "트리니다드 토바고", "미국"],
    "남아메리카": ["아르헨티나", "볼리비아", "브라질", "칠레", "콜롬비아", "에콰도르", "가이아나", "파라과이", "페루", "수리남", "우루과이", "베네수엘라"],
    "아프리카": ["알제리", "앙골라", "베냉", "보츠와나", "부르키나파소", "부룬디", "카보베르데", "카메룬", "중앙아프리카 공화국", "차드", "코모로", "콩고", "코트디부아르", "지부티", "이집트", "적도 기니", "에리트레아", "에스와티니", "에티오피아", "가봉", "감비아", "가나", "기니", "기니비사우", "케냐", "레소토", "라이베리아", "리비아", "마다가스카르", "말라위", "말리", "모리타니아", "모리셔스", "모로코", "모잠비크", "나미비아", "니제르", "나이지리아", "르완다", "상투메 프린시페", "세네갈", "세이셸", "시에라리온", "소말리아", "남아프리카 공화국", "남수단", "수단", "탄자니아", "토고", "튀니지", "우간다", "잠비아", "짐바브웨"],
    "오세아니아": ["오스트레일리아", "피지", "키리바시", "마셜 제도", "미크로네시아 연방", "나우루", "뉴질랜드", "팔라우", "파푸아뉴기니", "사모아", "솔로몬 제도", "통가", "투발루", "바누아투"]
}

# 생성할 데이터셋 개수와 각 데이터셋에 포함될 국가 개수 설정
num_datasets = 10
num_countries = 3

# 저장할 파일명 설정
filename = f"dataset_{num_datasets}_{num_countries}.csv"

with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(['Text', 'Completion'])

    # 2개부터 6개까지의 대륙 개수에 대해 반복
    for max_continents in range(2, 7):
        dataset_count = 0
        while dataset_count < num_datasets:
            try:
                # 랜덤하게 대륙 선택
                selected_continents = random.sample(list(un_countries.keys()), max_continents)
                selected_countries = []
                remaining_countries = num_countries

                # 선택된 대륙을 국가 수에 따라 정렬
                continent_info = [(continent, len(un_countries[continent])) for continent in selected_continents]
                continent_info.sort(key=lambda x: x[1])

                # 각 대륙에 할당할 국가 수 랜덤 선택
                for idx, (continent, max_available) in enumerate(continent_info):
                    if idx == len(continent_info) - 1:
                        num_countries_continent = remaining_countries
                    else:
                        min_countries = 2 if max_continents <= 4 else 1
                        max_assignable = min(max_available, remaining_countries - (len(continent_info) - idx - 1) * min_countries)
                        num_countries_continent = random.randint(min_countries, max_assignable)

                    selected = random.sample(un_countries[continent], num_countries_continent)
                    selected_countries.extend(selected)
                    remaining_countries -= num_countries_continent

                # 선택된 국가를 랜덤하게 섞어 데이터셋의 텍스트(Text)로 사용
                selected_countries_shuffled = random.sample(selected_countries, len(selected_countries))
                text = f"목록에서 나라를 대륙별로 분류해줘.\n\n{', '.join(selected_countries_shuffled)}"

                # 해당 국가들을 대륙별로 분류한 결과를 완성 텍스트(Completion)로 사용
                completion = "목록에 있는 나라들을 대륙별로 분류하면 다음과 같습니다\n\n"
                for continent in selected_continents:
                    countries = [c for c in selected_countries if c in un_countries[continent]]
                    if countries:
                        completion += f"{continent}: {', '.join(countries)}\n\n"

                # 생성된 데이터셋을 CSV 파일에 저장
                writer.writerow([text, completion.strip()])
                dataset_count += 1
            except ValueError:
                continue

# 최종적으로 생성된 데이터셋의 파일명 출력
print(f"데이터셋이 성공적으로 생성되었습니다. 파일명: {filename}")
```

도움말

- 데이터셋에 대한 가이드는 링크를 참고하실 수 있습니다. [https://hyperclova.navercorp.com/tuning/api/dataset](https://hyperclova.navercorp.com/tuning/api/dataset)

초기에는 튜닝 데이터셋의 국가를 대륙별로 나열하여 사용하였습니다.

그러나 이렇게 튜닝된 모델로 랜덤한 국가 목록을 평가했을 때, 오류가 많이 발생하는 문제가 있었습니다.

이 문제를 해결하기 위해, 튜닝 데이터셋의 국가 목록을 랜덤하게 섞어 사용했습니다. 그 결과, 모델의 성능이 크게 향상되었습니다.

## 튜닝 준비

### Base Model

- HCX-003
- HCX-DASH-001

### 튜닝 데이터 개수

- 50개
- 100개 ~ 1,000개
- 2,000개
- 10,000개

### 튜닝 세팅

- Method: LORA
- Task Type: GENERATION
- Train Epochs: 4
- Learning Rate: 1e-4
- Top K: 0
- Top P: 0.6
- Max Tokens: 256
- Repetition Penalty: 1.2
- Temperature: 0.5

도움말

- 두 모델 모두 base model로 시작하여, 튜닝 데이터 크기를 점진적으로 늘려가며 성능 변화를 관찰하였습니다.
- 이러한 세팅을 통해, 각 모델이 다양한 튜닝 데이터 크기에서 어떻게 성능이 변화하는지 분석할 수 있었습니다.

## 튜닝 과정

---

```python
import base64
import json
import http.client
import requests
```

```python
class CreateTaskExecutor:
   def __init__(self, host, client_id, client_secret, access_token=None):
       self._host = host
       self._client_id = client_id
       self._client_secret = client_secret
       self._encoded_secret = base64.b64encode('{}:{}'.format(self._client_id, self._client_secret).encode('utf-8')).decode('utf-8')
       self._access_token = access_token

   def _refresh_access_token(self):
       headers = {
           'Authorization': 'Basic {}'.format(self._encoded_secret)
       }

       conn = http.client.HTTPSConnection(self._host)
       conn.request('GET', '/v1/auth/token?existingToken=true', headers=headers)
       response = conn.getresponse()
       body = response.read().decode()
       conn.close()

       token_info = json.loads(body)
       self._access_token = token_info['result']['accessToken']

   def _send_request(self, create_task_request):
       headers = {
           'Authorization': 'Bearer {}'.format(self._access_token)
       }
       files = {
           'trainingDataset': (create_task_request['trainingDataset'].split("/")[-1], open(create_task_request['trainingDataset'], 'rb'))
       }
       data = {key: value for key, value in create_task_request.items() if key != 'trainingDataset'}

       response = requests.post(
           f'https://{self._host}/v2/tasks',
           headers=headers,
           data=data,
           files=files
       )
       return response.json()

   def execute(self, create_task_request):
       if self._access_token is None:
           self._refresh_access_token()

       res = self._send_request(create_task_request)
       if res['status']['code'] == '40103':
           self._access_token = None
           return self.execute(create_task_request)
       elif res['status']['code'] == '20000':
           return res['result']
       else:
           return 'Error'

if __name__ == '__main__':
   create_task_executor = CreateTaskExecutor(
       host='api-hyperclova.navercorp.com',
       client_id='<client_id>', # API 정보에서 발급받은 client_id를 입력합니다.
       client_secret='<client_secret>' # API 정보에서 발급받은 client_secret을 입력합니다.
   )

   request_data = {
       'name': 'test', # 작업의 이름을 입력합니다.
       'model': '<model_name>', # 사용할 모델을 입력합니다.
       'method': 'LORA',
       'taskType': 'GENERATION',
       'trainEpochs': 4,
       'learningRate': 1e-4,
       'trainingDataset': '/Users/user/Downloads/train.csv', # 학습 데이터셋의 경로를 입력합니다.
   }

   response = create_task_executor.execute(request_data)
   print(response)
```

- 결과
  ```python
  {'id': 'ef9qj7h4', 'name': 'Tuning_Test', 'groupId': 'hkFMel', 'groupName': None, 'userId': '****', 'userName': None, 'userEmail': None, 'baseModelId': 42, 'baseModel': 'HCX-003',
   'tuningModelId': None, 'tuningModel': None, 'tuningPipeline': None, 'deployPipeline': None, 'dataset': {'id': 'c560a84d1ce34bea8b090e9f403e5ed2', 'type': 'NONE', 'tuningType': None, 'filePath': '/dataset/2024-05-13Z/c560a84d1ce34bea8b090e9f403e5ed2/c560a84d1ce34bea8b090e9f403e5ed2.csv',
   'fileName': 'Train.csv', 'fileSize': 322251, 'token': 20158, 'rowCount': 300, 'groupId': 'hkFMel', 'userId': '****', 'trainMethod': 'mle', 'bucket': None, 'accessKey': None, 'secretKey': None, 'createdDate': '2024-05-13T15:42:50+0900', 'updatedDate': '2024-05-13T15:42:50+0900'},
   'method': 'LORA', 'modelDeprecated': False, 'modelUseChat': True, 'tuningType': 'PEFT', 'taskType': 'GENERATION', 'trainEpochs': 4, 'learningRate': 0.0001, 'instructionMixinRatio': 0.0, 'useOnlyInstructionData': False,
   'status': 'WAIT', 'statusInfo': {'dataRows': None, 'numOfTokens': None, 'currStep': None, 'totalTrainSteps': None, 'currEpoch': None, 'totalTrainEpochs': None, 'estimatedTime': None, 'trainLoss': None, 'lossDiff': None, 'sendWeightSuccess': None, 'uploadedWeights': [], 'failureReason': None, 'endDatetime': None, 'currNumOfTokens': None}, 'checkpoint': None, 'createdClientType': 'API', 'modelLabel': '', 'createdDate': '2024-05-13T15:42:50+0900', 'updatedDate': '2024-05-13T15:42:50+0900'}
  ```

## 튜닝 결과 확인

튜닝 결과를 확인하려면 CLOVA Studio의 플레이그라운드 화면에서도 가능하지만, 한 번에 여러 가지 결과를 확인할 수 있는 방법도 있습니다. 아래 형식에 맞춰서 평가 데이터를 준비하고 코드를 실행하면, 로컬에 있는 평가 데이터셋을 사용하여 튜닝한 모델의 성능을 한번에 평가하고 결과를 확인할 수 있습니다.

### 평가 데이터셋 형식

엑셀 데이터셋은 반드시 "system"이라는 이름의 열과 "user"라는 이름의 열을 포함해야 하며, 각각 시스템 프롬프트와 사용자의 질문에 대응하는 내용을 적어야 합니다. 아래와 같은 형식으로 엑셀 파일을 구성합니다.

| system               | user                                         |
| -------------------- | -------------------------------------------- |
| 시스템 프롬프트 입력 | 사용자가 말할 것으로 기대되는 모든 발화 내용 |

이렇게 엑셀을 구성한 후 튜닝 파이썬 코드를 실행하면, 튜닝한 모델이 엑셀 데이터셋에 있는 `system`과 `user` 열에 따라 결과를 생성합니다. 각 행마다 시스템 프롬프트와 사용자 질문을 모델에 입력하고, 이에 대한 모델의 응답이 엑셀 파일로 생성됩니다.

```python
import time
import requests
import pandas as pd
```

```python
CLIENT_KEY = '<client_key>'
CLIENT_SECRET = '<client_secret>'
MODEL_NAME = '<model_name>'
MODEL_PARAMETERS = {
    "topP": 0.6,
    "topK": 0,
    "maxTokens": 256,
    "temperature": 0.5,
    "repeatPenalty": 1.2,
    "includeAiFilters": False,
}
INPUT_FILENAME = "평가 파일 경로나 파일 이름"
OUTPUT_FILENAME = "결과를 저장할 파일의 이름을 지어주기.xlsx"

def __send_requests(system: str, user: str, token: str):
    url = f"https://api-hyperclova.navercorp.com/v2/tasks/{튜닝 task id}/chat-completions" # 튜닝 task id는 자신이 튜닝한 작업의 taskid(=result.id) 입력하기. 예: iqserz99
    headers = {
        'Authorization': f"Bearer {token}"
    }
    body = MODEL_PARAMETERS.copy()
    body["messages"] = [{
        "role": "system",
        "content": system
    }, {
        "role": "user",
        "content": user
    }]
    result = requests.post(url=url, json=body, headers=headers).json()
    print(result["result"])
    return result["result"]["message"]

def __get_auth():
    url = "https://api-hyperclova.navercorp.com/v1/auth/token"
    response = requests.get(url=url, auth=(CLIENT_KEY, CLIENT_SECRET))
    result = response.json()
    return (result["result"]["accessToken"], result["result"]["expiresIn"])

if __name__ == '__main__':
    token, tokenExpiresIn = __get_auth()

    # test 를 위해 일부 row 만 실행하기 원하는 경우 예시
    # df = pd.read_excel(INPUT_FILENAME)[:5]
    df = pd.read_excel(INPUT_FILENAME)
    results_role = []
    results_content = []

    for i in df.itertuples():
        currentTimestamp = int(time.time() * 1000)
        if tokenExpiresIn < currentTimestamp + 60000:
            token, tokenExpiresIn = __get_auth()
        result = __send_requests(i.system, i.user, token)
        results_role.append(result['role'])
        results_content.append(result['content'])
    df.insert(2, "role", results_role, True)
    df.insert(3, "content", results_content, True)

    df.to_excel(OUTPUT_FILENAME, index=False)

```

## 튜닝 결과 분석

### 데이터셋 크기에 따른 모델 성능 변화 분석

HCX-003 모델과 HCX-DASH-001 모델의 데이터셋 크기 증가에 따른 잘못된 국가 개수와 데이터 문제 발생 확률을 비교 분석하였습니다.

### HCX-003 모델

- 데이터셋 크기가 증가함에 따라 누락 국가 수, 오분류 국가 수, 확장 국가 수가 점진적으로 감소하는 경향을 보입니다.
- 2,000개 이상의 데이터셋으로 튜닝 시 오류 발생 확률이 크게 감소하였습니다. (2% 이하)
- 10,000개 데이터셋으로 튜닝 시 모든 오류가 발생하지 않았습니다.

![스크린샷 2024-06-03 오후 5.19.40.png](https://github.com/ejehoon/NAVER_CLOUD-CLOVA_Studio/blob/main/%EA%B5%AD%EA%B0%80%20%EB%B6%84%EB%A5%98%20%ED%8A%9C%EB%8B%9D%20task/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-06-03_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.19.40.png)

- 10,000개 데이터셋으로 튜닝 시 모든 오류가 발생하지 않았습니다.

[HCX-003](https://github.com/ejehoon/NAVER_CLOUD-CLOVA_Studio/blob/main/%EA%B5%AD%EA%B0%80%20%EB%B6%84%EB%A5%98%20%ED%8A%9C%EB%8B%9D%20task/HCX-003%20d0096dbc5c074c709ea5f2ee4f457e79.csv)

### HCX-DASH-001 모델

- 데이터셋 크기 증가에 따른 성능 향상 폭이 HCX-003 모델에 비해 완만합니다.
- 2,000개 이상의 데이터셋 튜닝 시에도 오류 발생 확률이 37%로 HCX-003에 비해 상대적으로 높게 유지되었습니다.
  ![스크린샷 2024-06-03 오후 5.19.52.png](https://github.com/ejehoon/NAVER_CLOUD-CLOVA_Studio/blob/main/%EA%B5%AD%EA%B0%80%20%EB%B6%84%EB%A5%98%20%ED%8A%9C%EB%8B%9D%20task/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-06-03_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.19.52.png)

[HCX-DASH-001](https://github.com/ejehoon/NAVER_CLOUD-CLOVA_Studio/blob/main/%EA%B5%AD%EA%B0%80%20%EB%B6%84%EB%A5%98%20%ED%8A%9C%EB%8B%9D%20task/HCX-DASH-001%20f069cb4f38304938b0db2dc541479f54.csv)

### 국가 개수에 따른 오류 발생 확률 분석

주어진 국가 개수(10, 15, 20, 30개국)에 따른 오류 발생 확률을 HCX-003 모델과 HCX-DASH-001 모델로 비교하였습니다.

![스크린샷 2024-06-03 오후 5.20.04.png](https://github.com/ejehoon/NAVER_CLOUD-CLOVA_Studio/blob/main/%EA%B5%AD%EA%B0%80%20%EB%B6%84%EB%A5%98%20%ED%8A%9C%EB%8B%9D%20task/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-06-03_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.20.04.png)

![스크린샷 2024-06-03 오후 5.21.18.png](https://github.com/ejehoon/NAVER_CLOUD-CLOVA_Studio/blob/main/%EA%B5%AD%EA%B0%80%20%EB%B6%84%EB%A5%98%20%ED%8A%9C%EB%8B%9D%20task/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2024-06-03_%25E1%2584%258B%25E1%2585%25A9%25E1%2584%2592%25E1%2585%25AE_5.21.18.png)

도움말

- 두 모델 모두 국가 개수가 증가할수록 오류 발생 확률이 높아지는 경향을 보였습니다.

---

### 대륙 개수에 따른 오류 발생 확률 분석

주어진 대륙 개수(2, 3, 4, 5, 6 대륙)에 따른 오류 발생 확률을 HCX-003 모델과 HCX-DASH-001 모델로 비교하였습니다.

도움말

- 국가 개수에 비해 대륙 개수에 따른 오류 발생 확률의 변화가 뚜렷하지는 않습니다.
- 10,000개 데이터셋 튜닝 시 모든 대륙 개수에서 오류가 발생하지 않았습니다.
- HCX-DASH-001 모델은 2,000개 데이터셋까지 대륙 개수에 따른 뚜렷한 경향성이 나타나지 않음

---

## 맺음말

본 쿡북에서는 HyperCLOVA X의 모델인 HCX-003과 HCX-DASH-001을 활용하여 국가 분류 작업 시 발생하는 오류를 튜닝을 통해 해결하는 과정을 살펴보았습니다.

처음에는 튜닝 데이터셋을 대륙별로 분류하여 사용했으나, 이 방법으로 튜닝된 모델은 무작위 국가 목록을 평가할 때 많은 오류가 발생했습니다. 이 문제를 해결하기 위해 국가 목록을 무작위로 섞어 사용하자 성능이 크게 개선되었습니다.

50개, 100개 등 적은 수의 데이터셋으로 튜닝했던 모델들의 성능은 미흡했으나, 지속적인 튜닝을 통해 점진적으로 성능이 개선되는 것을 확인할 수 있었습니다. 또한 HCX-003 모델의 경우 100개 튜닝부터, HCX-DASH-001 모델의 경우 400개 튜닝부터 포맷에 맞는 출력 결과를 얻을 수 있었습니다.

HCX-DASH-001 모델은 HCX-003 모델에 비해 평균 응답 시간이 단축되고, 비용 효용성도 기존 대비 5분의 1 수준으로 절감되는 장점이 있습니다. 이를 고려할 때, 보다 많은 데이터셋을 활용한 튜닝이 HCX-DASH-001 모델의 성능 향상에 도움이 될 것으로 판단됩니다.

**[구글 스프레드시트]**

https://docs.google.com/spreadsheets/d/1mHQmUWRgvv3ST_RvwbOmpdDsJcSsNCgOrePnuefYCpg/edit?gid=1593768939#gid=1593768939
